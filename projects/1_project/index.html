<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Light Field Rendering on 3D Looking Glass Device - A Tutorial | Haoyu Wei </title> <meta name="author" content="Haoyu Wei"> <meta name="description" content="An end-to-end system taking as input pictures of holograms captured from different positions using a handheld device such as a mobile phone and display the reconstructed hologram video on a 3D looking glass holographic display device."> <meta name="keywords" content="computational imaging"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://whywww.github.io/projects/1_project/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Haoyu</span> Wei </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Light Field Rendering on 3D Looking Glass Device - A Tutorial</h1> <p class="post-description">An end-to-end system taking as input pictures of holograms captured from different positions using a handheld device such as a mobile phone and display the reconstructed hologram video on a 3D looking glass holographic display device.</p> </header> <article> <p>Haoyu Wei, Tzujui Liu, Pengxiao Hao, Florian Willomitzer, Oliver Cossairt</p> <p>EE 496, 2020 Win</p> <h2 id="poster">Poster</h2> <p><img width="100%" height="100%" src="https://github.com/whywww/ImageBed/blob/master/holoPoster.png?raw=true"></p> <h2 id="abstract">Abstract</h2> <p>Motivated by the need of hologram conservation, we built an end-to-end system that takes as input pictures of holograms captured from different positions using a handheld device such as a mobile phone and display the reconstructed hologram on a 3D looking glass holographic display device. Concretely, we first expand images of a hologram to a light field with multiplane image scene representation, then we generate the complete light field information needed for the looking glass device to display the reconstructed holograms.</p> <h2 id="method">Method</h2> <h3 id="light-field-rendering">Light Field Rendering</h3> <p>This part is based on the paper <a href="https://github.com/Fyusion/LLFF" rel="external nofollow noopener" target="_blank">Mildenhall et al. 2019</a></p> <ol> <li> <p>Taking Photos of your object.</p> <p>The guideline is you should use images where the maximum disparity between views is no more than about 64 pixels (watch the closest thing to the camera and don’t let it move more than ~1/8 the horizontal field of view between images). I recommend at least 6 photos and 20-30 images would be the best.</p> <p><img src="https://github.com/whywww/ImageBed/blob/master/holo.png?raw=true" alt="capguide"></p> </li> <li> <p>System installation &amp; Demo test</p> <p>The instructions by the authors are published on github. Here is the way I’m doing and some supplement.</p> <p>Clone the repo from github to your working folder. Make sure CUDA, docker and nvidia-docker are installed on your machine.</p> <p>Run this in the base directory to download a pretrained checkpoint, download a Docker image, and run code to generate MPIs and a rendered output video on an example input dataset:</p> <div class="language-bash highlighter-rouge"> <div class="highlight"><pre class="highlight"><code> <span class="c"># Download packages.</span>
 bash download_data.sh
 <span class="nb">sudo </span>docker pull bmild/tf_colmap
 <span class="nb">sudo </span>docker tag bmild/tf_colmap tf_colmap

 <span class="c"># Run docker environment. (Change directories accordingly. Run this every time you restart your docker.)</span>
 nvidia-docker run <span class="nt">-it</span> <span class="se">\</span>
     <span class="nt">--rm</span> <span class="se">\</span>
     <span class="nt">-v</span> /:/host <span class="se">\</span>
     <span class="nt">-v</span> /dir/for/harddrive/data:/dir/for/data/in/docker/environment <span class="se">\</span>
     <span class="nt">--workdir</span> /host<span class="nv">$PWD</span> <span class="se">\</span>
     tf_colmap

 <span class="c"># Run demo in docker</span>
 bash demo.sh
</code></pre></div> </div> <p>You should be able to see a video like <a href="https://github.com/Fyusion/LLFF/blob/master/imgs/fern.gif" rel="external nofollow noopener" target="_blank">this</a> in <code class="language-plaintext highlighter-rouge">data/testscene/outputs/test_vid.mp4</code></p> <p>Troubleshooting:</p> <ul> <li> <strong>File or dir not found in docker environment:</strong> Check the directories mounted to docker when running the docker environment. Avoid starting docker and running script in the same line. This may cause path confusion in docker environment.</li> <li> <strong>Trouble running demo.sh:</strong> run python scripts line by line in demo.sh, check where the problem is. Or redownload test dataset from <a href="http://people.eecs.berkeley.edu/~bmild/llff/data/testscene.zip" rel="external nofollow noopener" target="_blank">here</a> to get new update.</li> </ul> </li> <li> <p>test with your own images.</p> <p>Create a working directory named <code class="language-plaintext highlighter-rouge">scenedir</code> for example, and make a data directory named <code class="language-plaintext highlighter-rouge">images</code> inside it. Put your photos in <code class="language-plaintext highlighter-rouge">images</code>. The <code class="language-plaintext highlighter-rouge">scenedir</code> can be renamed as you like and placed in which ever dir path exists in docker. But <code class="language-plaintext highlighter-rouge">images</code> folder cannot be renamed.</p> <p>Check the format of your photos using <code class="language-plaintext highlighter-rouge">ll</code> command in linux. Make sure your <code class="language-plaintext highlighter-rouge">images</code> dir contains only those images, and they ends with <code class="language-plaintext highlighter-rouge">.png, .jpg</code> or <code class="language-plaintext highlighter-rouge">.JPG</code> and in the corresponding format.</p> <p>Note, You can convert image format easily in a linux command, for example:</p> <div class="language-bash highlighter-rouge"> <div class="highlight"><pre class="highlight"><code> <span class="k">for </span>file <span class="k">in</span> <span class="k">*</span>.png<span class="p">;</span> <span class="k">do </span>convert <span class="nv">$file</span> <span class="k">${</span><span class="nv">file</span><span class="p">/%.png/.jpg</span><span class="k">}</span><span class="p">;</span> <span class="k">done</span>
</code></pre></div> </div> <p>Now we can write our own bash script and try our photos. Here’s an example of mine.</p> <div class="language-bash highlighter-rouge"> <div class="highlight"><pre class="highlight"><code> <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span>0,1,2 python imgs2poses.py /host/mnt/scenedir/

 <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span>0,1,2 python imgs2mpis.py <span class="se">\</span>
         /host/mnt/scenedir/ <span class="se">\</span>
         /host/mnt/scenedir/mpis_720 <span class="se">\</span>
         <span class="nt">--height</span> 720

 <span class="nb">mkdir</span> /host/mnt/scenedir/outputs

 python imgs2renderpath.py <span class="se">\</span>
         /host/mnt/scenedir/ <span class="se">\</span>
         /host/mnt/scenedir/outputs/xaxis_path.txt <span class="se">\</span>
         <span class="nt">--x_axis</span>

 <span class="nb">cd </span>cuda_renderer <span class="o">&amp;&amp;</span> make <span class="o">&amp;&amp;</span> <span class="nb">cd</span> ..

 cuda_renderer/cuda_renderer <span class="se">\</span>
         /host/mnt/scenedir/mpis_720 <span class="se">\</span>
         /host/mnt/scenedir/outputs/xaxis_path.txt <span class="se">\</span>
         /host/mnt/scenedir/outputs/xaxis_vid.mp4 <span class="se">\</span>
         <span class="nt">-1</span> .8 0
</code></pre></div> </div> <p><code class="language-plaintext highlighter-rouge">CUDA_VISIBLE_DEVICES=0,1,2</code> specifies which GPU to use. Other parameters are described in ‘General step-by-step usage’ in the author’s github.</p> <p>Troubleshooting:</p> <ul> <li> <strong>PyramidCU::GenerateFeatureList: an illegal memory access was encountered:</strong> Some machine configurations might run into problems running the script imgs2poses.py. Try different GPUs in <code class="language-plaintext highlighter-rouge">CUDA_VISIBLE_DEVICES=0,1,2</code>. If the issue persists, try uncommenting <a href="https://github.com/Fyusion/LLFF/blob/master/llff/poses/colmap_wrapper.py#L33" rel="external nofollow noopener" target="_blank">this line</a> to stop COLMAP from using the GPU to extract image features.</li> <li> <strong>Error running the script:</strong> Check <code class="language-plaintext highlighter-rouge">colmap_output.txt</code> in <code class="language-plaintext highlighter-rouge">scenedir</code>. If there are images not registered or not paired, it might be the photos do not accord with the guidelines of the system, or image format is incorrect.</li> </ul> </li> <li> <p>Collect light field images.</p> <p>Here is a python script I wrote to cut all the frames from the video we got.</p> <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code> <span class="kn">import</span> <span class="n">cv2</span>
 <span class="kn">import</span> <span class="n">os</span>

 <span class="c1"># TODO: Please change the directories
</span> <span class="n">outdir</span> <span class="o">=</span> <span class="sh">'</span><span class="s">/Users/haoyuwei/Desktop/splittedvid_lion/</span><span class="sh">'</span>
 <span class="n">video_dir</span> <span class="o">=</span> <span class="sh">'</span><span class="s">/Users/haoyuwei/mnt/scenedir/outputs/xaxis_vid.mp4</span><span class="sh">'</span>

 <span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">VideoCapture</span><span class="p">(</span><span class="n">video_dir</span><span class="p">)</span>
 <span class="k">try</span><span class="p">:</span>
     <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">outdir</span><span class="p">):</span>
         <span class="n">os</span><span class="p">.</span><span class="nf">makedirs</span><span class="p">(</span><span class="n">outdir</span><span class="p">)</span>
 <span class="k">except</span> <span class="nb">OSError</span><span class="p">:</span>
     <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Error: cannot create dir of output data.</span><span class="sh">'</span><span class="p">)</span>

 <span class="nb">id</span> <span class="o">=</span> <span class="mi">0</span>
 <span class="nf">while</span><span class="p">(</span><span class="bp">True</span><span class="p">):</span>
     <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="p">.</span><span class="nf">read</span><span class="p">()</span>

     <span class="n">fn</span> <span class="o">=</span> <span class="n">outdir</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="nb">id</span><span class="p">)</span> <span class="o">+</span><span class="sh">'</span><span class="s">.png</span><span class="sh">'</span>
     <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Creating...</span><span class="sh">'</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
     <span class="n">cv2</span><span class="p">.</span><span class="nf">imwrite</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">frame</span><span class="p">)</span>

     <span class="nb">id</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div> </div> </li> <li> <p>Put images to Looking Glass Device</p> <p>For installation of the Looking Glass Device, please refer to the official documentation <a href="https://docs.lookingglassfactory.com/Gettingstarted/images/Hardware%20Setup%20Guide%20-%20Looking%20Glass%2015-6%20Inch%20Dev%20Kit.pdf" rel="external nofollow noopener" target="_blank">here</a>. Then, download the HoloPlay Service software <a href="https://lookingglassfactory.com/software/holoplay-service" rel="external nofollow noopener" target="_blank">here</a> and follow the instruction in the official website <a href="https://docs.lookingglassfactory.com/HoloPlayService/?_ga=2.99792022.987789442.1584998920-1680746765.1570509609" rel="external nofollow noopener" target="_blank">here</a>.</p> <p>After you successfully connect the Looking Glass Device, download the <a href="https://lookingglassfactory.com/devtools/lightfield-photo-app" rel="external nofollow noopener" target="_blank">lightfield photo app</a>.</p> <p>After installation, navigate to the folder where you installed the app, create a new folder in <strong>Lightfield Photosets</strong>, copy all the light field images we get from the previous step into the folder. Activate the app, then you should see a new photoset in the app. Click it, then click <strong>choose photos</strong>, and select all the lightfield images in that folder. You should see the images being loaded onto the Looking Glass Device. Click <strong>Set Croping</strong>, and adjust the focus and field of view for best display effects.</p> <p>For additional informations, please refer to the official documentation in <a href="https://docs.lookingglassfactory.com/LightfieldPhoto/" rel="external nofollow noopener" target="_blank">here</a>.</p> </li> </ol> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Haoyu Wei. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>